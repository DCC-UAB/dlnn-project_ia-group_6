{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mgd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import utils\n",
    "import cnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = os.path.expanduser(\"/Users/noramendoza/Desktop/DL_project/data/fma_small\")\n",
    "TRACKS_FILE = utils.load(\"/Users/noramendoza/Desktop/DL_project/TRACKS.csv\")\n",
    "TRACKS_FILE.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset containing *spectrograms* of song tracks and their *labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data = mgd.MusicGenreDataset(AUDIO_DIR, TRACKS_FILE, apply_spectrogram=True)\n",
    "print(f\"There are {len(music_data)} samples in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, l, p = music_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p)\n",
    "print(l)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_spectrogram(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for s,l,p in music_data: \n",
    "    X.append(s)\n",
    "    y.append(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not able to get all 8000 files, but we can take at least 4470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "# Determine the maximum size in each dimension\n",
    "max_size = torch.Size(max(s.size(i) for s in X) for i in range(X[0].ndim))\n",
    "\n",
    "# Pad all tensors to the max size\n",
    "X = [pad(t, (0, max_size[-1] - t.size(-1), 0, max_size[-2] - t.size(-2))) for t in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on your labels and transform the labels\n",
    "y_numeric = encoder.fit_transform(y)\n",
    "\n",
    "# Now you can create a tensor from y_numeric\n",
    "y = torch.tensor(y_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split the data into a training set and a temporary set using an 80-20 split.\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then split the temporary set into validation and testing sets using a 50-50 split.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import s\n",
    "\n",
    "data = X_train # Your data (list of tensors)\n",
    "\n",
    "# Define DataLoader parameters\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "\n",
    "# Create an instance of your custom dataset\n",
    "train_custom_dataset = s.final_dataset(data, y_train)\n",
    "test_dataset = s.final_dataset(X_test, y_test)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_dataloader = DataLoader(train_custom_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "model.train_model(train_dataloader, test_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have had trouble dealing with the model. At first we worked with a small number of files, files that we first convert to spectrograms, then slice them into (1,128,128) shape and then convert them to tensors. Working with these, and with the existing model, we achieved an accuracy of more than 60%. \n",
    "\n",
    "But then we tried the same for the whole set, and since we had trouble splitting the spectrograms, we opt not to do it and therefore now we have this problem. We know where the problem is but we are having much trouble solving it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
